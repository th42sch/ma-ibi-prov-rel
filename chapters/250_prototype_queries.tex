% !TeX spellcheck = en_GB
% =================================================================
\chapter{Prototype Queries and Answers}
\label{chap:prototype_queries}

As a first step towards delineating the type of queries that should be covered by our approach,
we examine the query patterns introduced in Section~\ref{sec:background} more closely.
Those will serve as a point of reference for the analysis of the available data sources
in Chapter~\ref{chap:analysis},
and they will be generalised by the abstract framework developed in Chapter~\ref{chap:modelling}.
That framework will provide a rigorous definition of the queries that can be formulated
within it.

% -----------------------------------------------------------------
\section{Prototype Queries}
\label{sec:prototype_queries}

The query patterns introduced in Section~\ref{sec:background} are the following.
%
\begin{enumerate}
  \item[\exaquery{1}]
    Who read work $W$, in which manifestation and in which year?
  \item[\exaquery{2}]
    Which exemplars of work $W$ were passed from one of its owners to a collaborator (or a student)?
  \item[\exaquery{3}]
    What are the relationships between the recipients of work $W$
    (or of manifestation $M$ of $W$ or of exemplar $C$ of $W$, respectively)?
\end{enumerate}
%
These query patterns have been identified
as important examples by personal communication
with provenance researchers\todo{ask more experts},%
\footnote{Dietrich Hakelberg, Research Library Gotha of the University of Erfurt}
which justifies the choice of considering them as \emph{prototypical}.

Obviously, the question arises whether these prototypical query patterns are representative
for the range of queries that provenance researchers are interested in asking.
Answering that question would require systematic analysis of queries relevant to or useful for researchers.
Such an analysis would need to comprise an extensive interview study
based on very generic questions of a predominantly open-ended nature,
requiring a labour-intensive evaluation.
Given that this thesis focusses on the technical prerequisites and realisation,
such a study is clearly outside its scope. However, since the general framework that we will develop
is informed by the available data sources
and designed to cover a wide range of possible queries,
it is reasonable to assume that tools developed on its basis will be helpful for provenance researchers.
In subsequent work, when our method will hopefully have been implemented in a prototype tool,
the extent to which researchers' needs are served can be determined by means of a more focussed user study
with more specific questions, which in turn can inform possible extensions of the framework.

% -----------------------------------------------------------------
\section{Manual Answer Retrieval}
\label{sec:manual_answering}

In order to demonstrate how a researcher could proceed (manually) when answering a query,
we take Pattern~\exaquery{2} and fix work $W$ to be the seminal work \emph{De revolutionibus orbium coelestium}
(short: \emph{De revolutionibus}; English translation: \emph{On the Revolutions of the Heavenly Spheres}) \autocite{Kopernikus1543}
by the astronomer Nicolaus Copernicus (1473–1543).
We thus consider the following concrete query.
%
\begin{enumerate}
  \item[\exaquery{2$'$}]
%    Which exemplars of \emph{De revolutionibus} were owned by scientists who passed them on to a student?
    Which exemplars of \emph{De revolutionibus} were owned by some scientist who passed them on to a student?
\end{enumerate}
%
When answering \exaquery{2$'$}, an obvious way to proceed is the following:
first, our researcher finds exemplars of \emph{De revolutionibus} 
in online catalogues of libraries and library networks. For each such exemplar, they then inspect the provenance entries
that name owners who were people (not corporate bodies). Finally, our researcher will have to find those names in databases such as
authority files or Wikidata and, for each entry, explore the specified profession (\enquote{scientist})
and relationships to other people (\enquote{student}).

For example, the online catalogue (OPAC) of the Gotha Research Library of the University of Erfurt (Forschungsbibliothek Gotha) lists two printed exemplars
of \emph{De revolutionibus} \autocite{OPACDeRev}.
%\footnote{%
%  \url{https://opac.uni-erfurt.de/DB=1/CMD?ACT=SRCHA&IKT=1016&SRT=YOP&TRM=tit+de+revolutionibus+and+per+kopernikus+and+jah+15**+and+bbg+a*}%
%}
One of those bears the signature \sig{Druck~4°~00466}, and its provenance entries name the following previous owners  \autocite{OPACDeRevPPN}:
%\footnote{%
%  \url{https://opac.uni-erfurt.de/LNG=EN/DB=1/XMLPRS=N/PPN?PPN=567506266}%
%}
%
\begin{itemize}
  \item
    Hieronymus Tilesius (1529–1566): autograph and date 1551
  \item
    NN: note, date 1553, name scraped out
  \item
    Johann Hommel (1518–1562), autograph
  \item
    Valentin Thau (1531–1575), note (greek proverb, possibly not denoting ownership)
  \item
    Ernest II, Duke of Saxe-Gotha-Altenburg (1745–1804): stamp/seal, initial
  \item
    Ducal Library, Gotha (a predecessor organisation of Gotha Research Library): stamp marking a duplicate
  \item
    Ernestine Gymnasium, Gotha: stamp
  \item
    Landesbibliothek Gotha: stamp
\end{itemize}
%
Our researcher can immediately decide that they can ignore the second entry (no name given) and the last three entries (corporate bodies).
For the remaining four entries, our researcher follows the links given in the OPAC to the Integrated Authority File (GND) of the German National Library \autocite{DNBCatalogue}.
%\footnote{%
%  \url{https://katalog.dnb.de/EN/home.html?v=plist}%
%}
On inspection of these entries, it turns out that Ernest II was a regent and very probably not a scientist,
and that the other three people---Tilesius, Hommel, and Thau---had professions such as theologian,
mathematician, and astronomer, which qualifies them as scientists. Furthermore, Hommel's entry
contains a reference to Thau with the relationship \enquote{has student}
(and Thau's entry contains the inverse reference to Hommel).
From this reference, our researcher can conclude that two scientists in the teacher-student relation
have both possessed the exemplar. 

Unfortunately, the data available does not imply that Hommel passed the exemplar (directly) to Thau;
furthermore, the provenance entry for Thau raises doubts as to whether Thau was really an owner of the exemplar.
Therefore, the retrieved data can only be regarded as a \emph{candidate answer}
which entails the hypothesis that the found exemplar was passed from Hommel to Thau.
Our researcher can now engage in further research in order to verify that hypothesis.

\todo[inline,caption={}]{
  \parbox{.99\linewidth}{%
    \begin{itemize}
      \item
        Discuss instances of \exaquery{1} or \exaquery{3}?
      \item
        Add further prototypical query patterns?
      \item
        Explain how \exaquery{1}--\exaquery{3} differ from each other (extend remarks from Section~\ref{sec:background})?
    \end{itemize}
  }%
}

% -----------------------------------------------------------------
\section{The Quality of Query Answers}
\label{sec:quality_of_answers}

Our simple example already illustrates that the quality of query answers
strongly depends on the quality of the underlying data,
regardless of whether answers are obtained manually or automatically. 
In particular, missing or spurious data will lead to missing or spurious answers.
Before we begin to deal with automated query answering,
we need to analyse the sources of missing or spurious data and their effects on the answers obtained.

For the sake of a principled discussion, we call the set of answers to a query obtained by some manual or automatic procedure
an \emph{answer set}, and we call the (set of) answers that the query has in reality the \emph{true answers} and the \emph{true answer set}.
In the above example, the answer set obtained by the described manual process consists of the single answer
\enquote{\sig{Druck~4°~00466}}, if we assume that our researcher interprets the data retrieved generously
(i.e., as an indication that Thau might have been an owner and might have received the book directly from Hommel)
and draws additional conclusions (i.e., that every mathematician or astronomer is a scientist).
The true answer set is not known and will most probably never be known; it is a term of rather philosophical nature.

Ideally, both answer sets should coincide.
Incomplete data may cause the answer set to exclude some true answers,
and spurious data may cause it to contain some answers that are not true.
We call the respective answers \emph{missing} and \emph{spurious}.
On the basis of our example, we can identify four distinct causes for data being incomplete or spurious,
as discussed in the following. We use the word \emph{term} as an umbrella term for concepts (such as \enquote{scientist})
and relations (such as \enquote{is student of}).
%
\begin{enumerate}
  \item
    In the example, there is no information available on whether any of the persons involved is indeed
    a \emph{scientist}.
    However, information on more specific professions (e.g., theologian,
    mathematician, and astronomer) is available, and the information that,
    e.g., Thau and Hommel were scientists has to be derived based on general knowledge
    of the world.
    The same effect can occur with relations instead of concepts:
    if \exaquery{2} were to ask for family members instead of collaborators or students,
    then the data would presumably only support more specific relations
    such as \enquote{has sister} or \enquote{has father}, and relationships using
    \enquote{has family member} would need to be derived.

    More generally speaking, terms can be missing in the data sources
    because\todo{find proof in the lit./with experts? Ask DH?}
    membership in them is implicit, for example, from membership in more specific terms.
    If the query uses such terms, then the answer set is always empty
    unless the person or machine determining the answers makes derivations based on their
    knowledge of the world.

    Clearly, it would not be advisable to attempt adding all implicit knowledge to the data
    because that would massively inflate the data,
    as most terms have several superordinate concepts or relations and,
    furthermore, implicit knowledge is not restricted to taxonomic knowledge.
    \todo[inline]{Explain this further? A case for ontologies!}
  \item
    In the example, there is no information available on whether any of the owners of the exemplar
    \emph{passed it on} to another owner. Similarly,
    attempts to answer instances of Query Pattern~\exaquery{1} will have to deal
    with the problem that there is no information available as to who \emph{read} books.
    
    More generally speaking, terms can be missing in the data sources
    because they are not recorded at all, as a consequence of general design decisions
    for the data source. The reasons for such decisions can be manifold:
    for example, relationships such as who actually \emph{read} a book are very hard to confirm,
    or terms may not be part of the fixed vocabulary for a data field in a source.\todo{find example?}
    If the query uses such terms, then the answer set is always empty, as in Case~1.
  \item    
    In the example, it is possible that single owners of the exemplar or single relationships between owners
    have not been recorded because no evidence has been found yet.
    More generally, concept memberships or relationships can be missing sporadically,
    which may lead to missing answers.
  \item
    In the example, if the provenance entry on Hommel is incorrect, then the answer obtained on the grounds
    of that entry is incorrect.
    More generally, spurious concept memberships or relationships may lead to spurious answers.
\end{enumerate}
%
These cases reveal a striking qualitative difference concerning the effects of data incompleteness or spuriousness
on the answer set: Cases~3 and~4 have effects on single answers only, i.e., some answers are missing or spurious.
However, Cases~1 and~2 generally make \emph{all} answers missing unless further provisions are made.
In the above example, such ``provisions'' might include the conclusion that mathematicians etc.\ are scientists.
and the hypothesis that Thau was an owner and received the book directly from Hommel.
Getting back to the general objective of this thesis, it is appropriate to consider
answers as \emph{candidates} that necessitate (and inspire) further research.
For this purpose, spurious answers (in manageable numbers) are less harmful than missing answers.
Consequently, it is important to find ways to avoid missing answers without generating too many spurious answers.
In other words, it is desirable to obtain an answer set that is a slight \emph{overapproximation}
of the true answer set.

% -----------------------------------------------------------------
\section{From Manual to Automated Query Answering}
\label{sec:manual_vs_automated}

The manual process that we have described in Section~\ref{sec:manual_answering}
is cumbersome, laborious, and prone to errors and omissions for several reasons:
The search in library catalogues for exemplars of works and their provenances requires expert skills.
Catalogues with potential matches need to be selected manually,
and each catalogue needs to be queried individually, using its own search functionality and syntax. \todo{give examples of commonalities (OPAC) and differences (discovery vs. OPAC)?}
The traversal through all retrieved exemplars and the pursuit of each potential relevant provenance entry per exemplar 
multiplies the amount of manual work necessary.
Finally, it is not clear what an effective and efficient way to \enquote{explore} relationships would be:
while it is easy to find direct relationships such as \enquote{is student of} in the view for a person's entry
in databases such as GND or Wikidata, there are relationships that cannot be discovered easily by hand,
e.g., \enquote{$P_1$ and $P_2$ are students of the same scholar}.

These considerations suggest that query answering will
strongly benefit from automated support,
which can help reduce the amount of manual work, integrate heterogeneous data sources,
incorporate background knowledge (e.g., every mathematician is a scientist),
and discover relationships between entities that are not necessarily direct.
We envisage a software tool that enables researchers to formulate queries 
and which computes answers consulting data sources selected by the user.
The vocabulary used for formulating queries should be based on the vocabulary
present in the data sources, but it should also include terms such as \enquote{scientist} or \enquote{read},
which are not recorded in the data, as discussed in
Section~\ref{sec:quality_of_answers}. The tool thus needs to implement ways
to map those terms with the available vocabulary, as well as techniques
for integrating data from heterogeneous sources.
It is our general vision that the software tool will serve as an instrument for prospectively finding interesting
candidates that inspire further research.
In the remainder of this thesis, we want to lay the foundations and develop a precise method
that can serve as a basis for a future implementation of this tool.

